{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b750c2de",
   "metadata": {},
   "source": [
    "## Correlations\n",
    "\n",
    "### Correlations with random data\n",
    "\n",
    "- Create two random vectors of length 30 and plot them (you many need to call `pyplot.show` to see the picture or use `pyplot.savefig` to save it to a file). Compute their means and variances and their covariance. Compute Pearson's correlation coefficient from these values. Use `numpy.corrcoef` to check yourself.\n",
    "- Use numpy arrays' `.argsort()` method to convert values to their ranks (you will need to use it twice; try to understand why). Use the ranks to compute Spearman's correlation coefficient. Use `scipy.stats.spearmanr` to check yourself.\n",
    "\n",
    "**NB**: if you use `np.cov` to compute covariances, set `ddof=0`, otherwise the result will be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad659893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41af16fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some work\n",
    "# 1. create random vectors\n",
    "v1 = np.random.rand(1, 30)\n",
    "v2 = np.random.rand(1, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d0482ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.61215008 0.23034629 0.9208522  0.29749845 0.33812577 0.32547784\n",
      "  0.0163865  0.84590151 0.10148003 0.67743685 0.77966505 0.7171349\n",
      "  0.31317093 0.333088   0.57124411 0.10979827 0.99528893 0.75014322\n",
      "  0.74448353 0.08183517 0.96844287 0.65067687 0.78255203 0.63391108\n",
      "  0.92672895 0.28747416 0.54487538 0.51744806 0.57587853 0.732573  ]]\n",
      "[[0.65909996 0.78741679 0.90953841 0.85711919 0.2179472  0.66481138\n",
      "  0.11194795 0.62504436 0.68071454 0.59811956 0.27210884 0.00942484\n",
      "  0.86460322 0.01106118 0.17980113 0.48766799 0.82997247 0.91485458\n",
      "  0.47925447 0.79218309 0.72679661 0.03232906 0.73989696 0.48343548\n",
      "  0.96645464 0.77204612 0.46278322 0.58560881 0.56959405 0.13802857]]\n"
     ]
    }
   ],
   "source": [
    "print(v1)\n",
    "print(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89fcdc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(v1, v2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a70ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1mean = np.mean(v1)\n",
    "v2mean = np.mean(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3f227a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5460689518894615, 0.5476554891569164)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1mean, v2mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "171a169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1var = v1.var()\n",
    "v2var = v2.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c411b089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07858508287576527, 0.0849492408052679)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1var, v2var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "130b1e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_v2_cov = np.cov(v1, v2, ddof=0)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67d6e676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009880039394289303"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1_v2_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45af57ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12092298730211458"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_test = v1_v2_cov / np.sqrt(v1var) / np.sqrt(v2var)\n",
    "pearson_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78d6cd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12092298730211455"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(v1, v2)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95ecb6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6, 19,  8, 15,  1, 25,  3, 12,  5, 13,  4, 27, 26, 14, 28,  0,\n",
       "        23, 21,  9, 11, 29, 18, 17, 10, 22,  7,  2, 24, 20, 16]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b8a171b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61215008, 0.23034629, 0.9208522 , 0.29749845, 0.33812577,\n",
       "        0.32547784, 0.0163865 , 0.84590151, 0.10148003, 0.67743685,\n",
       "        0.77966505, 0.7171349 , 0.31317093, 0.333088  , 0.57124411,\n",
       "        0.10979827, 0.99528893, 0.75014322, 0.74448353, 0.08183517,\n",
       "        0.96844287, 0.65067687, 0.78255203, 0.63391108, 0.92672895,\n",
       "        0.28747416, 0.54487538, 0.51744806, 0.57587853, 0.732573  ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b799e92f",
   "metadata": {},
   "source": [
    "### Correlations with controlled data\n",
    "- Create a vector `x` of consecutive values using `np.arange`. Create several others vectors, including\n",
    "    * `x` with some noise added (e.g., add `np.random.normal(loc=0, scale=0.1, size=30)` to `x`)\n",
    "    * a linear transformation of `x` (of the form $a + bx$, $a$ and $b$ scalars) with some noise\n",
    "    * a non-linear monotonic transformation of `x` (e.g., `log`, `exp`) with some noise\n",
    "    * a non-monotonic transformation of `x` (e.g., a quadratic if `x` has both positive and negative values) with some noise\n",
    "- Make scatter plots for `x` vs. the other vector and calcucate Pearson's and Spearmans correlation coefficients.\n",
    "- Add outliers to `x` (e.g., replace some values with very big ones; if you add values, don't forget to add to `y` as well). Plot new `x` and `y` and check how outliers affect correlation coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ba6b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3245d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98346202",
   "metadata": {},
   "source": [
    "## Linear models\n",
    "\n",
    "### Simple linear regression\n",
    "\n",
    "You can reuse the vectors $x$ and $a + bx + \\epsilon$ from the previous exercise or create new _x_ and _y_. Now we'll try to recover $a$ and $b$ from the data.\n",
    "\n",
    "- Use a `LinearRegression` object to fit a linear model and extract $a$ and $b$.\n",
    "- Plot $x$ and $y$ and add a regression line.\n",
    "- Standardise $x$ and $y$ (subtract their means and divide them by their standard deviations), find the coefficients again, compare $b$ with the correlation coefficient for standardised vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ab1a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf80cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df49720",
   "metadata": {},
   "source": [
    "### Adding more predictors\n",
    "\n",
    "- Create a random matrix `X` where each row corresponds to an observation and columns correspond to variables. Make `y` a linear combination of these columns with some noise added and try to recover the coefficients of your linear combination using vanilla `LinearRegression`.\n",
    "- Try making two columns of `X` highly correlated (e.g., copy a column and add some noise). See how this affects the estimation of the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "387c23db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925654d5",
   "metadata": {},
   "source": [
    "### Using regularisation\n",
    "\n",
    "- Use `Ridge` and `Lasso` to compute coefficients based on the matrix with correlated columns. Compute the resulting coefficients with those provided by the vanilla model. Interpret the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df0017a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b291e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61fc44a",
   "metadata": {},
   "source": [
    "### Real data\n",
    "\n",
    "Let's analyse some real data from the `diabetes` dataset.\n",
    "\n",
    "(If you are using R, ask someone to dump the dataset into a .csv file for you.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e38400b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19aa9001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, total serum cholesterol\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, total cholesterol / HDL\n",
      "      - s5      ltg, possibly log of serum triglycerides level\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "diabetes = datasets.load_diabetes()\n",
    "print(diabetes.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a775a785",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417921fa",
   "metadata": {},
   "source": [
    "Separate 20 rows as a test dataset (use random rows or any interval you like). Train different models (vanilla, ridge, lasso) on the remaining data and use the `.predict()` method of the fitted model to predict the test response. Compute the mean squared error of the prediction manually or using `sklearn.metrics.mean_squared_error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd0122b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1504deab",
   "metadata": {},
   "source": [
    "Try to be more systematic in selectic hyperparameters for ridge and lasso by using _cross-validation_: separate the rows of **X** and values of _y_ into five groups. Train the model on 4 groups and use the fifth for testing. Average over 5 results (mean-squared errors) for each value of $\\lambda$ from some set (e.g., `[0.01, 0.1, 1, 10, 100]`) and model.\n",
    "\n",
    "What combination of the penalty value and a model gives the best prediction accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43966f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07992e65",
   "metadata": {},
   "source": [
    "## Significance testing\n",
    "\n",
    "Take the best model from the previous section and use permutation testing and bootstrapping to compute a _p_-value and a confidence interval for the predictor _bp_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa22f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
